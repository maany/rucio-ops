{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checksum Processing and Verification ( adler32 )\n",
    "\n",
    "For the DIDs that were present in both, rucio dumps and seal dumps, we will validate whether the checksums reported in both dumps are the same or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Range\n",
    "We need to pick a time range used to filter the DIDs from the dumps. The end time is limited by the fact that we do not have all the checksums for the DIDs in the SEAL dumps after a certain time. We will use the following time range for the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date_start_str = '20220101' # YYYYMMDD\n",
    "date_end_str = '20220801' # YYYYMMDD\n",
    "\n",
    "date_start = datetime.strptime(date_start_str, '%Y%m%d')\n",
    "date_end = datetime.strptime(date_end_str, '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checksum processing\n",
    "\n",
    "In this section, we will process the checksums from the Rucio and SEAL dumps to make them comparable.\n",
    "\n",
    "## Checksums calculated by SEAL\n",
    "\n",
    "The `data/seal/checksums/entries_{start_date}_{end_date}.csv` file contains the checksums (adler32, md5, sha256) calculated by SEAL for the DIDs available on their storage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Entries: 516978\n",
      "Total Size: 343.429 TB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from core.utils import bytesToTB\n",
    "dir = 'data/seal/checksums'\n",
    "entries_file = f'{dir}/entries_{date_start_str}_{date_end_str}.csv'\n",
    "\n",
    "entries = pd.read_csv(entries_file)\n",
    "entries['path'] = entries['path'].str.replace('rucio/', '')\n",
    "\n",
    "total_size_entries = entries['size_bytes'].sum()\n",
    "\n",
    "print(f'Num Entries: {len(entries)}')\n",
    "print(f'Total Size: {bytesToTB(total_size_entries)} TB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data/seal/checksums/errors_{start_date}_{end_date}.csv` file contains entries that for which the checksum could not be calculated by SEAL and the specific errors that occurred.\n",
    "\n",
    "- Most of the errors indicate 404 Not Found, which means SEAL has data for the file, but the last few chunks did not complete transfer\n",
    "- Entries with a 500 Internal Server Error are essentially the same as the 404, but the in addition the to the chunk(s) missing, the metadata record could not be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    data15_13TeV/DAOD_PHYSLITE.22956626._000109.po...\n",
      "1    data15_13TeV/DAOD_PHYSLITE.22956716._000120.po...\n",
      "2    data15_13TeV/DAOD_PHYSLITE.22956771._000467.po...\n",
      "3    data16_13TeV/DAOD_PHYSLITE.22956954._000091.po...\n",
      "4    data16_13TeV/DAOD_PHYSLITE.22956983._000021.po...\n",
      "Name: path, dtype: object\n",
      "Num Errors: 4387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/zbc_xnv17ggfqczysm3_5g_80000gn/T/ipykernel_97244/2825224956.py:2: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  errors = pd.read_csv(errors_file, index_col=False)\n"
     ]
    }
   ],
   "source": [
    "errors_file = f'data/seal/checksums/errors_{date_start_str}_{date_end_str}.csv'\n",
    "errors = pd.read_csv(errors_file, index_col=False)\n",
    "errors['path'] = errors['path'].str.replace('rucio/', '')\n",
    "print(f'Num Errors: {len(errors)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checksums stored by Rucio\n",
    "\n",
    "We will load the consistent did's ( subset of rucio dumps ) and filter for rows for the selected time range. The consistent did's are the ones that are present in both the rucio dumps and the seal dumps. This file was prepared in the `manual_auditor` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Consistent DIDs: 2654663\n"
     ]
    }
   ],
   "source": [
    "consistent_dids_file = f'data/outputs/consistent_dids_20220101-20230410.csv'\n",
    "consistent_dids = pd.read_csv(consistent_dids_file)\n",
    "\n",
    "consistent_dids['creation_date'] = pd.to_datetime(consistent_dids['creation_date'])\n",
    "consistent_dids['update_date'] = pd.to_datetime(consistent_dids['update_date'])\n",
    "consistent_dids['size'] = pd.to_numeric(consistent_dids['size'])\n",
    "\n",
    "print(f'Num Consistent DIDs: {len(consistent_dids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we filter the consistent did's for the selected time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Consistent DIDs in Date Range: 793013\n"
     ]
    }
   ],
   "source": [
    "consistent_dids_in_time_range = consistent_dids[(consistent_dids['creation_date'] <= date_end)]\n",
    "\n",
    "print(f'Num Consistent DIDs in Date Range: {len(consistent_dids_in_time_range)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Checksums from SEAL\n",
    "\n",
    "The `consistent_dids_in_time_range` DataFrame contains the DIDs that are present in both the rucio dumps and the seal dumps in the selected time range. Therefore, the DIDs provided by SEAL in their `entries` and `errors` DataFrames should also be present in the `consistent_dids_in_time_range` DataFrame ( except for the `dark_dids`). We will check if this is the case.\n",
    "\n",
    "The entries that are present in the `consistent_dids_in_time_range` file but are not present in the `entries` or `errors` files are missing checksums from SEAL. We will check if there are any such entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Missing Checksums from SEAL: 271658\n",
      "For the time range 2022-01-01 00:00:00 to 2022-08-01 00:00:00: \n"
     ]
    }
   ],
   "source": [
    "dids_missing_checksums = consistent_dids_in_time_range[~consistent_dids_in_time_range['path'].isin(entries['path'])]\n",
    "\n",
    "# check if the dids missing checksums are not in the errors\n",
    "\n",
    "dids_missing_checksums = dids_missing_checksums[~dids_missing_checksums['path'].isin(errors['path'])]\n",
    "\n",
    "print(f'Num Missing Checksums from SEAL: {len(dids_missing_checksums)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the time range 2022-01-01 00:00:00 to 2022-08-01 00:00:00: 793013 DIDs registered in Rucio were available at SEAL.\n",
      "Of these, checksums were provided by SEAL for 516978 DIDs. SEAL could not generate checksums for 4387 DIDs and these files should be marked as lost.\n",
      "271658 DIDs were missing checksums from SEAL.\n"
     ]
    }
   ],
   "source": [
    "print(f\"For the time range {date_start} to {date_end}: {len(consistent_dids_in_time_range)} DIDs registered in Rucio were available at SEAL.\")\n",
    "print(f\"Of these, checksums were provided by SEAL for {len(entries)} DIDs. SEAL could not generate checksums for {len(errors)} DIDs and these files should be marked as lost.\")\n",
    "print(f\"{len(dids_missing_checksums)} DIDs were missing checksums from SEAL.\")\n",
    "\n",
    "missing_checksums_filename = f'data/outputs/dids_missing_checksums_{date_start_str}_{date_end_str}.csv'\n",
    "dids_missing_checksums.to_csv(missing_checksums_filename, index=False)\n",
    "print(f\"Missing checksums DIDs written to {missing_checksums_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checksum Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
