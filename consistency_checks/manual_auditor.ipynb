{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize SEAL dumps\n",
    "---\n",
    "\n",
    "In this step, we load the files that contain the dumps provided by SEAL and store them in a TimeRangeSourceData format. This format is a dictionary that contains the following keys:\n",
    "start: the start time of the dump\n",
    "end: the end time of the dump\n",
    "file: the file that contains the dump\n",
    "source: the source of the dump ( SEAL or Rucio ). In this case, it will be SEAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TimeRangeSourceData(start=datetime.datetime(2022, 1, 1, 0, 0), end=datetime.datetime(2022, 10, 1, 0, 0), file='data/seal/rucio_20220101_20221001.csv', source='SEAL'), TimeRangeSourceData(start=datetime.datetime(2022, 10, 1, 0, 0), end=datetime.datetime(2022, 12, 1, 0, 0), file='data/seal/rucio_20221001_20221201.csv', source='SEAL'), TimeRangeSourceData(start=datetime.datetime(2022, 12, 1, 0, 0), end=datetime.datetime(2023, 2, 1, 0, 0), file='data/seal/rucio_20221201_20230201.csv', source='SEAL'), TimeRangeSourceData(start=datetime.datetime(2023, 1, 31, 0, 0), end=datetime.datetime(2023, 4, 10, 0, 0), file='data/seal/rucio_20230131_20230410.csv', source='SEAL')]\n"
     ]
    }
   ],
   "source": [
    "from infratructure.repository.data_repository import list_files\n",
    "from datetime import datetime\n",
    "from core.entity import TimeRangeSourceData\n",
    "dir = 'data/seal'\n",
    "data_files = list_files(dir)\n",
    "data_files = [x.split('.')[0] for x in data_files]\n",
    "seal_dumps_time_ranges = []\n",
    "for file in data_files:\n",
    "    _, start_date, end_date = file.split('_')\n",
    "    start_date = datetime.strptime(start_date, '%Y%m%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y%m%d')\n",
    "    seal_dumps_time_ranges.append(TimeRangeSourceData(start=start_date, end=end_date, source='SEAL', file=f\"{dir}/{file}.csv\"))\n",
    "\n",
    "print(seal_dumps_time_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the continuity of the dumps\n",
    "\n",
    "For all the files that we have, we will check if the time intervals are chained. This means that the end time of a dump is the same as the start time of the next dump. If this is not the case, we will print an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2023-02-01 00:00:00 != 2023-01-31 00:00:00\n",
      "Check files data/seal/rucio_20221201_20230201.csv and data/seal/rucio_20230131_20230410.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "# sort by start date\n",
    "seal_dumps_time_ranges = sorted(seal_dumps_time_ranges, key=lambda x: x.start)\n",
    "\n",
    "# check if the entrires form a continuous time range\n",
    "for i in range(1, len(seal_dumps_time_ranges)):\n",
    "    if seal_dumps_time_ranges[i].start != seal_dumps_time_ranges[i-1].end:\n",
    "        print(f\"Error: {seal_dumps_time_ranges[i-1].end} != {seal_dumps_time_ranges[i].start}\")\n",
    "        print(f\"Check files {seal_dumps_time_ranges[i-1].file} and {seal_dumps_time_ranges[i].file}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the dumps\n",
    "\n",
    "Load the dumps as pandas dataframes and merge them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                name  \\\n",
      "0  HITS.10075481._000432.pool.root.1   \n",
      "1  HITS.10075481._000433.pool.root.1   \n",
      "2  HITS.10075481._000434.pool.root.1   \n",
      "3  HITS.10075481._000435.pool.root.1   \n",
      "4  HITS.10075481._000444.pool.root.1   \n",
      "\n",
      "                                           path      size  sha256  \\\n",
      "0  mc15_14TeV/HITS.10075481._000432.pool.root.1  16535161     NaN   \n",
      "1  mc15_14TeV/HITS.10075481._000433.pool.root.1  16438598     NaN   \n",
      "2  mc15_14TeV/HITS.10075481._000434.pool.root.1  16186512     NaN   \n",
      "3  mc15_14TeV/HITS.10075481._000435.pool.root.1  17000891     NaN   \n",
      "4  mc15_14TeV/HITS.10075481._000444.pool.root.1  17039812     NaN   \n",
      "\n",
      "                  mtime  \n",
      "0  2022-05-09T19:54:06Z  \n",
      "1  2022-05-09T19:53:36Z  \n",
      "2  2022-05-09T19:53:27Z  \n",
      "3  2022-05-09T19:55:58Z  \n",
      "4  2022-05-09T19:53:01Z  \n",
      "                              name                                       path  \\\n",
      "0  HITS.580376._000432.pool.root.1  mc11_7TeV/HITS.580376._000432.pool.root.1   \n",
      "1  HITS.743322._010041.pool.root.1  mc12_8TeV/HITS.743322._010041.pool.root.1   \n",
      "2  HITS.743322._010052.pool.root.1  mc12_8TeV/HITS.743322._010052.pool.root.1   \n",
      "3  HITS.743322._010273.pool.root.1  mc12_8TeV/HITS.743322._010273.pool.root.1   \n",
      "4  HITS.743322._010313.pool.root.1  mc12_8TeV/HITS.743322._010313.pool.root.1   \n",
      "\n",
      "        size  sha256                 mtime  \n",
      "0  710329961     NaN  2022-11-28T14:25:16Z  \n",
      "1  251031588     NaN  2022-11-28T14:26:12Z  \n",
      "2  245757323     NaN  2022-11-28T14:27:13Z  \n",
      "3  245945634     NaN  2022-11-28T14:26:49Z  \n",
      "4  244013012     NaN  2022-11-28T14:26:07Z  \n",
      "                                     name  \\\n",
      "0  DAOD_PHYS.29308474._000001.pool.root.1   \n",
      "1  DAOD_PHYS.29308474._000002.pool.root.1   \n",
      "2  DAOD_PHYS.29308476._000001.pool.root.1   \n",
      "3  DAOD_PHYS.29308476._000002.pool.root.1   \n",
      "4  DAOD_PHYS.29308478._000001.pool.root.1   \n",
      "\n",
      "                                                path      size  sha256  \\\n",
      "0  data22_900GeV/DAOD_PHYS.29308474._000001.pool....  71754355     NaN   \n",
      "1  data22_900GeV/DAOD_PHYS.29308474._000002.pool....   7459434     NaN   \n",
      "2  data22_900GeV/DAOD_PHYS.29308476._000001.pool....  62883153     NaN   \n",
      "3  data22_900GeV/DAOD_PHYS.29308476._000002.pool....  10287388     NaN   \n",
      "4  data22_900GeV/DAOD_PHYS.29308478._000001.pool....  90007406     NaN   \n",
      "\n",
      "                  mtime  \n",
      "0  2023-01-10T03:25:20Z  \n",
      "1  2023-01-25T03:01:54Z  \n",
      "2  2023-01-19T13:34:43Z  \n",
      "3  2023-01-18T07:58:54Z  \n",
      "4  2023-01-18T09:02:17Z  \n",
      "                                     name  \\\n",
      "0                      user.ddmadmin.test   \n",
      "1  DAOD_PHYS.21504358._000001.pool.root.1   \n",
      "2  DAOD_PHYS.21504358._000002.pool.root.1   \n",
      "3  DAOD_PHYS.21504358._000003.pool.root.1   \n",
      "4  DAOD_PHYS.21504358._000004.pool.root.1   \n",
      "\n",
      "                                            path        size  sha256  \\\n",
      "0               user/ddmadmin/user.ddmadmin.test           5     NaN   \n",
      "1  valid1/DAOD_PHYS.21504358._000001.pool.root.1  1499810505     NaN   \n",
      "2  valid1/DAOD_PHYS.21504358._000002.pool.root.1  1424658970     NaN   \n",
      "3  valid1/DAOD_PHYS.21504358._000003.pool.root.1  1605376695     NaN   \n",
      "4  valid1/DAOD_PHYS.21504358._000004.pool.root.1  1681636809     NaN   \n",
      "\n",
      "                  mtime  \n",
      "0  2023-03-02T12:46:36Z  \n",
      "1  2023-02-12T18:27:43Z  \n",
      "2  2023-02-09T12:40:46Z  \n",
      "3  2023-02-13T09:37:21Z  \n",
      "4  2023-02-13T08:28:37Z  \n"
     ]
    }
   ],
   "source": [
    "selected_time_ranges = seal_dumps_time_ranges[0:]\n",
    "\n",
    "for selected_time_range in selected_time_ranges:\n",
    "    df = pd.read_csv(selected_time_range.file)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object stream_session.<locals>.new_funct at 0x11969c6a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rucio.api.did import list_dids\n",
    "\n",
    "list_dids(scope='user.mlassnig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
